# -*- coding: utf-8 -*-
"""Stable Diffusion Fine-Tuning V2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13CkZozK6iSoRneaXi0qFka_88_GQTQNg

# Install Libraries
"""

# Commented out IPython magic to ensure Python compatibility.
# %pip install -U diffusers
# %pip install -U transformers
# %pip install -U accelerate
# %pip install datasets
# %pip install bitsandbytes
# %pip install git+https://github.com/huggingface/diffusers.git
# %pip install peft

"""# Base Model Testing"""

# Helper function to display images
def plot_images(images):
    from matplotlib import pyplot as plt
    plt.figure()
    f, axarr = plt.subplots(1, len(images), figsize=(20,10))
    for ax, img in zip(axarr.flatten(), images):
        ax.imshow(img)
        ax.axis('off')
    plt.show()

# Importing the base model of stable diffusion 2
import torch
from diffusers import StableDiffusionPipeline, DiffusionPipeline

model_id = "stabilityai/stable-diffusion-2-1"

pipe_2 = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16)
pipe_2 = pipe_2.to("cuda")

# Calling the model
prompt = "a photo of an astronaut riding a horse on mars"
image = pipe_2(prompt).images[0]
image
# image.save("astronaut_rides_horse.png")

image

"""### Images produced from Base Model"""

prompt = "A Pokemon Card of the format tag team,with pokemon of type dragon and ghost with the title Gratina in the Tag Team form from Sun & Moon with an Electric type Pikachu as the buddy of the Tag Team"
images = pipe_2(prompt, num_images_per_prompt=3).images
plot_images(images)

prompt = "A pokemon of type dragon and ghost with the title Gratina in the Tag Team form from Sun & Moon with an Electric type Pikachu as the buddy of the Tag Team"
images = pipe_2(prompt, num_images_per_prompt=3).images
plot_images(images)

prompt = "A Basic Pokemon Card of type electric with the title Pikachu"
images = pipe_2(prompt, num_images_per_prompt=3).images
plot_images(images)

prompt = "A Pokemon of type electric with the title Pikachu"
images = pipe_2(prompt, num_images_per_prompt=3).images
plot_images(images)

prompt = "A Basic Pokemon Card of type Darkness with the title Absol G 70 HP of rarity Rare Holo from the set Supreme Victors."
images = pipe_2(prompt, num_images_per_prompt=3).images

plot_images(images)

prompt = "a photo of a charaizard on mars doing computer science"
images = pipe_2(prompt).images[0]
images

prompt = "a photo of a pokemon charaizard in the kanto region with Ask Ketchum from pokemon with a pikachu"
images = pipe_2(prompt).images[0]
images

"""### Clear the GPU Memory"""

# Flush the GPU memory to be able to run the training
del pipe_2
del images

# Collect the gpu memory and emptying it
import gc
gc.collect()
torch.cuda.empty_cache()

"""# Fine Tuning Base Model on Pokemon Card Dataset

## LoRA Training

### Fine-tuning LoRA
"""

# Needed dependencies for LoRA
from peft import LoraConfig
!git clone https://github.com/huggingface/diffusers.git

# Commented out IPython magic to ensure Python compatibility.
# # Variables needed for the LoRA training
# %%capture
# %env MODEL_NAME=stabilityai/stable-diffusion-2-1
# %env OUTPUT_DIR=pokemon-card-model
# %env HUB_MODEL_ID=pokemon-lora
# %env DATASET_NAME=vwu142/Pokemon-Card-Plus-Pokemon-Actual-Image-And-Captions-13000

# Write token login for Hugging Face
from google.colab import userdata
from huggingface_hub import login
login(token = userdata.get('HF_WRITE_TOKEN'))

!accelerate launch --mixed_precision="fp16"  diffusers/examples/text_to_image/train_text_to_image_lora.py \
  --pretrained_model_name_or_path=$MODEL_NAME \
  --mixed_precision="fp16" \
  --dataset_name=$DATASET_NAME --caption_column="caption"\
  --dataloader_num_workers=8 \
  --resolution=512 --center_crop --random_flip \
  --train_batch_size=1 \
  --gradient_accumulation_steps=4 \
  --max_train_steps=1500 \
  --learning_rate=1e-04 \
  --max_grad_norm=1 \
  --lr_scheduler="cosine" --lr_warmup_steps=0 \
  --output_dir=${OUTPUT_DIR} \
  --push_to_hub \
  --hub_model_id=${HUB_MODEL_ID} \
  --report_to=wandb \
  --checkpointing_steps=500 \
  --validation_prompt="Ludicolo" \
  --seed=1337

"""### Calling the Model with the Weights"""

from huggingface_hub import model_info

# LoRA weights ~3 MB
model_path = "vwu142/pokemon-lora"

info = model_info(model_path)
model_base = info.cardData["base_model"]
print(model_base)

# Importing the Diffusion model with the weights added
import torch
from diffusers import StableDiffusionPipeline, DPMSolverMultistepScheduler

pipe = StableDiffusionPipeline.from_pretrained(model_base, torch_dtype=torch.float16)
pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)
pipe.unet.load_attn_procs(model_path)
pipe.to("cuda")

"""### Images produced from LoRA Fine-Tuned Model"""

prompt = "A Pokemon Card of the format tag team,with pokemon of type dragon and ghost with the title Gratina in the Tag Team form from Sun & Moon with an Electric type Pikachu as the buddy of the Tag Team"
images = pipe(prompt, num_inference_steps=50, num_images_per_prompt=3).images
plot_images(images)

prompt = "A pokemon of type dragon and ghost with the title Gratina in the Tag Team form from Sun & Moon with an Electric type Pikachu as the buddy of the Tag Team"
images = pipe(prompt, num_inference_steps=50, num_images_per_prompt=3).images
plot_images(images)

prompt = "A Basic Pokemon Card of type electric with the title Pikachu"
images = pipe(prompt, num_inference_steps=100, num_images_per_prompt=3).images
plot_images(images)

prompt = "A Pokemon of type electric with the title Pikachu"
images = pipe(prompt, num_inference_steps=100,  num_images_per_prompt=3).images
plot_images(images)

image = pipe("Green pokemon with menacing face", num_inference_steps=50).images[0]
image

image = pipe("Green pokemon with a cute face that looks like turtwig", num_inference_steps=50).images[0]
image

"""## Non-LoRA

### Fine-tuning Non-LoRA
"""

# Needed dependencies
!git clone https://github.com/huggingface/diffusers.git
# Cloning the dataset
!git clone https://huggingface.co/datasets/vwu142/Pokemon-Card-Plus-Pokemon-Actual-Image-And-Captions-13000

# Commented out IPython magic to ensure Python compatibility.
# # Env variables needed
# %%capture
# %env MODEL_NAME=stabilityai/stable-diffusion-2-1
# # Name of dataset
# %env dataset_name=vwu142/Pokemon-Card-Plus-Pokemon-Actual-Image-And-Captions-13000
# # No need to train the model for long to see meaningful results.
# %env max_training_epochs = 100

# Non-LoRA
!accelerate launch diffusers/examples/text_to_image/train_text_to_image.py \
  --pretrained_model_name_or_path=$MODEL_NAME \
  --dataset_name=$dataset_name --caption_column="caption"\
  --use_ema \
  --use_8bit_adam \
  --resolution=512 --center_crop --random_flip \
  --train_batch_size=1 \
  --gradient_accumulation_steps=8 \
  --gradient_checkpointing \
  --mixed_precision="fp16" \
  --max_train_steps=$max_training_epochs \
  --learning_rate=1e-05 \
  --max_grad_norm=1 \
  --lr_scheduler="constant" --lr_warmup_steps=0 \
  --output_dir="pokemon-card-model"

"""## Calling the Fine-Tuned Model"""

def plot_images(images):
    from matplotlib import pyplot as plt
    plt.figure()
    f, axarr = plt.subplots(1, len(images), figsize=(20,10))
    for ax, img in zip(axarr.flatten(), images):
        ax.imshow(img)
        ax.axis('off')
    plt.show()

import torch
from diffusers import StableDiffusionPipeline, DiffusionPipeline, DPMSolverMultistepScheduler

pipe = StableDiffusionPipeline.from_pretrained('pokemon-card-model', torch_dtype=torch.float16)
pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)
pipe = pipe.to("cuda")

"""### Images produced from the variety of models fine-tuned"""

prompt = "A Pokemon Card of the format tag team,with pokemon of type dragon and ghost with the title Gratina in the Tag Team form from Sun & Moon with an Electric type Pikachu as the buddy of the Tag Team"
images = pipe(prompt, num_images_per_prompt=3).images
# Learning rate: 1e-05 | steps = 100 | Data = 15k
plot_images(images)

prompt = "A pokemon of type dragon and ghost with the title Gratina in the Tag Team form from Sun & Moon with an Electric type Pikachu as the buddy of the Tag Team"
images = pipe(prompt, num_images_per_prompt=3).images
# Learning rate: 1e-05 | steps = 100 | Data = 15k
plot_images(images)

prompt = "A pokemon of type electric with the title Pikachu in the Vmax form"
images = pipe(prompt, num_images_per_prompt=3).images
# Learning rate: 1e-05 | steps = 100 | Data = 15k
plot_images(images)

prompt = "A Basic Pokemon Card of type electric with the title Pikachu in the Vmax form"
images = pipe(prompt, num_images_per_prompt=3).images
# Learning rate: 1e-05 | steps = 100 | Data = 15k
plot_images(images)

prompt = "A Basic Pokemon Card of type electric with the title Pikachu"
images = pipe(prompt, num_images_per_prompt=3).images
# Learning rate: 1e-05 | steps = 100 | Data = 13k
plot_images(images)

prompt = "A Basic Pokemon Card of type electric with the title Pikachu"
images = pipe(prompt, num_images_per_prompt=3).images
# Learning rate: 1e-05 | steps = 100 | Data = 11k
plot_images(images)

prompt = "Make a Basic pokemon card of type electric with the title Pikachu and a VSTAR verison of it"
images = pipe(prompt, num_images_per_prompt=3).images
# Learning rate: 1e-05 | steps = 100 | Data = 11k
plot_images(images)

prompt = "Make a pokemon card of Absol where it a dark type and a VSTAR verison of it"
images = pipe(prompt, num_images_per_prompt=3).images
# Learning rate: 1e-05 | steps = 300 | Data = 9k
plot_images(images)

prompt = "A Basic Pokemon Card of type electric with the title Pikachu"
images = pipe(prompt, num_images_per_prompt=3).images
# Learning rate: 1e-05 | steps = 300 | Data = 9k
plot_images(images)

prompt = "A Basic Pokemon Card of type electric with the title Pikachu"
images = pipe(prompt, num_images_per_prompt=3).images
# Learning rate: 1e-05 | steps = 50 | Data = 7k
plot_images(images)

prompt = "A Basic Pokemon Card of type electric with the title Pikachu"
images = pipe(prompt, num_images_per_prompt=3).images
# Learning rate: 1e-05 | steps = 75 | Data = 7k
plot_images(images)

# Learning rate: 1e-05 | steps = 100
plot_images(images)

prompt = "A Basic Pokemon Card of type Darkness with the title Absol G 70 HP of rarity Rare Holo from the set Supreme Victors."
images = pipe(prompt, num_images_per_prompt=3).images
# Learning rate: 5e-05
plot_images(images)

prompt = "A Basic Pokemon Card of type Darkness with the title Absol G 70 HP of rarity Rare Holo from the set Supreme Victors."
images = pipe(prompt, num_images_per_prompt=3).images
# Learning rate: 1e-05 | steps = 100
plot_images(images)

prompt = "A Basic Pokemon Card of type Darkness with the title Absol G 70 HP of rarity Rare Holo from the set Supreme Victors."
images = pipe(prompt, num_images_per_prompt=3).images
# Learning rate: 5e-05
plot_images(images)

prompt = "A Basic Pokemon Card of type Darkness with the title Absol G 70 HP of rarity Rare Holo from the set Supreme Victors."
images = pipe(prompt, num_images_per_prompt=3).images
# 5000 images used to fine-tune the model
plot_images(images)

prompt = "A Basic Pokemon Card of type Darkness with the title Absol G 70 HP of rarity Rare Holo from the set Supreme Victors."
images = pipe(prompt, num_images_per_prompt=3).images
# 3000 images used to fine-tune the model
plot_images(images)

prompt = "A Basic Pokemon Card of type Darkness with the title Absol G 70 HP of rarity Rare Holo from the set Supreme Victors."
images = pipe(prompt, num_images_per_prompt=3).images
# 1500 images used to fine-tune the model
plot_images(images)

"""## Clear GPU Memory"""

del pipe
del images

import gc
gc.collect()
torch.cuda.empty_cache()

"""## Push the Model to Hugging Face"""

from google.colab import userdata
from huggingface_hub import login
login(token = userdata.get('HF_WRITE_TOKEN'))

pipe.push_to_hub("vwu142/fine-tuned-pokemon-and-pokemon-card-generator-13000")

"""# Calling new Fine-tuned Model from our Hugging Face"""

# Building the pipeline with the Fined-tuned model from Hugging Face
from diffusers import DiffusionPipeline

pipeline = DiffusionPipeline.from_pretrained("vwu142/fine-tuned-pokemon-and-pokemon-card-generator-13000")
pipeline.scheduler = DPMSolverMultistepScheduler.from_config(pipeline.scheduler.config)
pipeline = pipeline.to("cuda")

prompt = "A Pokemon Card of the format tag team,with pokemon of type dragon and ghost with the title Gratina in the Tag Team form from Sun & Moon with an Electric type Pikachu as the buddy of the Tag Team"
images = pipeline(prompt, num_images_per_prompt=3).images
plot_images(images)

prompt = "A pokemon of type dragon and ghost with the title Gratina in the Tag Team form from Sun & Moon with an Electric type Pikachu as the buddy of the Tag Team"
images = pipeline(prompt, num_images_per_prompt=3).images
plot_images(images)

prompt = "A Basic Pokemon Card of type electric with the title Pikachu"
images = pipeline(prompt, num_images_per_prompt=3).images
plot_images(images)

prompt = "A Pokemon of type electric with the title Pikachu"
images = pipeline(prompt, num_images_per_prompt=3).images
plot_images(images)

prompt = "A Pokemon of type electric with the title Pikachu"
images = pipeline(prompt, num_images_per_prompt=3).images
plot_images(images)

prompt = "A Basic Pokemon Card of type electric with the title Pikachu"
images = pipeline(prompt, num_images_per_prompt=3).images
# 15K images used to fine-tune the model
plot_images(images)

plot_images(images)

prompt = "A Basic Pokemon Card of type electric with the title Pikachu"
images = pipeline(prompt, num_images_per_prompt=3).images
# 7000 images used to fine-tune the model
plot_images(images)

prompt = "A Basic Pokemon Card of type electric with the title Pikachu"
images = pipeline(prompt, num_images_per_prompt=3).images
# 5000 images used to fine-tune the model
plot_images(images)

prompt = "A Basic Pokemon Card of type Darkness with the title Absol G 70 HP of rarity Rare Holo from the set Supreme Victors."
images = pipeline(prompt, num_images_per_prompt=3).images
plot_images(images)

del pipeline
del images

"""# Fine-tuning the Fine-tuned model"""

!git clone https://github.com/huggingface/diffusers.git
!git clone https://huggingface.co/datasets/vwu142/Pokemon_Card_Actual_Image_And_Captions_1500

# Commented out IPython magic to ensure Python compatibility.
# %%capture
# %env MODEL_NAME=vwu142/fine-tuned-pokemon-card-generator-1500
# %env dataset_name=Pokemon_Card_Actual_Image_And_Captions
# # No need to train the model for long to see meaningful results.
# %env max_training_epochs = 50

!accelerate launch diffusers/examples/text_to_image/train_text_to_image.py \
  --pretrained_model_name_or_path=$MODEL_NAME \
  --dataset_name=$dataset_name --caption_column="caption"\
  --use_ema \
  --use_8bit_adam \
  --resolution=512 --center_crop --random_flip \
  --train_batch_size=1 \
  --gradient_accumulation_steps=4 \
  --gradient_checkpointing \
  --mixed_precision="fp16" \
  --max_train_steps=$max_training_epochs \
  --learning_rate=1e-05 \
  --max_grad_norm=1 \
  --lr_scheduler="constant" --lr_warmup_steps=0 \
  --output_dir="pokemon-card-model"